---
slug: broken-link-check-tools
title: 我的断链扫描工具选型之路
authors: [yilin]
---

## 前情提要

在我的第一篇博客最后，我给自己出了一份将来要更新的博客列表。拖更了两周，现在回来了。其实我想了很久要从哪里开始说起，想来想去，还是先从简单的开始吧。

## 背景信息

### 什么是断链

断链是网页上加了一个超链接，单击该链接跳转至另一个网站时，无法访问该网站，返回 404。

断链分两种：internal 和 external。internal 指的是站内跳转，external 指的是外部跳转。

产生断链的原因非常简单：链接失效了。导致链接失效的原因有很多。例如：结构层级变化、手动输入的时候输错了、页面下架了等等。

### 为什么要干掉断链

谁都不希望在阅读产品文档的时候，点一个链接返回 404。在安装或快速入门这一类的文档中，开发者为了节省时间和精力，通常会将安装所需的依赖浓缩成一个个超链接。但是如果在这个时候，链接断了，相当于阻碍了新用户进行初步了解和入门，不仅体验感差，而且会流失新用户，降低产品口碑，问题非常严重。其次，搜索引擎会依据网页内的有效链接和断链数量对其进行评分，断链越多，评分越低，在搜索结果中返回的排名越低。

### 怎么干掉断链

背景信息里面说了，产生断链的原因是链接失效了。这时候该怎么修复它们呢？以下是我常用的三个思路：

1. 直接删除：如果自己判断这个链接是多余的，那就可以直接删掉，不用花时间找正确的替代了。

1. 修改为正确链接：如果自己判断这个链接是有用的，那就需要自己去找正确的链接，排查的过程也非常简单，大部分都是结构层级变化或手动输入的时候输错了。

1. 替换为其他链接：如果自己判断这个链接是有用的，但上一个步骤找了半天找不到正确的链接，那么可以换个思路：我找个替代品总可以吧？

## 为什么不用 GitHub 集成的 CI 工具做扫描？

这个时候有人可能就要问了：GitHub Action 里面已经有各种官方和自制的 CI 工具，为什么不用它们去做这件事情呢？

原因无他，概况为三个字：局限性。

首先是 CI 工具自身的局限性：

1. 只能在提交 pull request 的时候，那一刻没问题不代表接下来都没问题。

1. 只能测当前 pull request 造成了哪些断链。

1. 大部分只能测 internal，而不能测 external。

其次是我自己的局限性：如果要满足自己的需求，则需要一定的客制化代码开发，我不具备这个能力。

## 选型过程中碰到的问题

由于 GitHub Action 和 我自身的局限性，我选择了另一条道路：Google 搜一下看看，不止我一个人有这个需求，肯定会有对应的产品解决我的问题。经过一些时间的搜索和尝试，我确实发现了几款工具，应该可以满足我的大部分需求。

1. [W3C Link Checker](https://validator.w3.org/checklink)

1. [Online Broken Link Checker](https://www.brokenlinkcheck.com/)

1. [Link Alarm](http://www.linkalarm.com/about/)

1. [Web Link Validator](http://www.relsoftware.com/wlv/)

1. [Dr Link Check](https://www.drlinkcheck.com/)

### 工具各项属性对比

|名称|成本|准确性|便捷性|
|:------|:------|:------|:------|
|W3C Link Checker|免费|中等，会有误报|不方便，要自己洗数据|
|Online Broken Link Checker|免费|中等，会有误报|不方便，要自己洗数据|
|Link Alarm|免费|中等，会有误报|不方便，要自己洗数据|
|Web Link Validator|免费|中等，会有误报|不方便，要自己洗数据|
|Dr Link Check|收费，订阅制，$198 一年|高等，会有误报|方便，支持表达式过滤误报|

试了一圈之后，最初锁定的是 Online Broken Link Checker，再加上 W3C Link Checker 作为后备项。两个工具同时挂掉的概率非常小，虽然要自己把数据导出到本地再清洗，但是它们绝对能够满足日常使用。

### 选择免费版工具的过程中踩了哪些坑

Online Broken Link Checker 和 W3C Link Checker 的槽点也蛮多。

1. 时间长，不够用户友好：空运行一次半小时起步，手抖不小心关了浏览器得重来。

1. dry run 数据不一致：连续跑几次，返回的数据都不一样。

1. 工具 service down：Online Broken Link Checker 曾经有一段时间不可用了，404 检测工具自己变成 404 了，还满讽刺的。幸好我准备了 plan B 哈哈哈。

1. 数据清洗费时费力：原表格的排列和我想看的有出入，要自己导进去 Excel 再重新整理，非常耗时间。

1. 不支持过滤误报：算是 dry run 数据不一致的副作用之一，我觉得可以有误报，但是不支持过滤就很烦了。

## 为什么最后选了 Dr.LinkCheck

经历过 Online Broken Link Checker service down 一段时间之后，我决定还是得换个收费的工具试试看，就换到了 Dr.LinkCheck。因为 Dr.LinkCheck 的收费标准是分阶段的，超过 1000 个链接要收钱，超过 2000 个链接又要加钱。所以我综合了当前的链接数量和日后可能会新增的链接数量，选择了最便宜的包年订阅套餐。

### Dr.LinkCheck 的优势

1. 数据更精准：对比下来它是最精确的。

1. Dashboard 可视化：使用门槛低，在页面上点就行。

1. 支持项目隔离：可以自己控制 scope，局部和全局都 ok。

1. 不用自己做数据清理。

1. 支持正则表达式过滤误报。

1. 扫描在后台运行，与 UI 解耦，再也不用担心手抖误关页面了。

1. 有客服有邮箱，回复还算快。

1. 没事帮别人扫一扫，提个 pr 修问题刷脸。

### Dr.LinkCheck 的缺点

贵（可能是我的问题？）

## 使用 Dr.LinkCheck 达到了什么效果

1. Rancher 中文文档网站 0 断链。

1. 自动化，设置双周扫描，有问题会发邮件。

1. 解放生产力，再也不用花大块的时间盯着这个问题了。

1. Impress 领导和同事。你们都没资源没时间干的事情，我搞定了。最后这个订阅费用也通过其他途径报销了，美滋滋。

## 后续计划

加大力度，继续使用 Dr.LinkCheck。

